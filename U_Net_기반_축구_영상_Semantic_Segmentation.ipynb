{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# âš½ï¸ U-Net ê¸°ë°˜ ì¶•êµ¬ ì˜ìƒ Semantic Segmentation (11 Classes)\n",
        "\n",
        "\n",
        "## 1. í”„ë¡œì íŠ¸ ëª©ì \n",
        "ì¶•êµ¬ ê²½ê¸° ì¥ë©´ ì´ë¯¸ì§€ì—ì„œ ê° í”½ì…€ì„ 11ê°œ í´ë˜ìŠ¤(ì”ë””/ì„ ìˆ˜/ê³¨ëŒ€/ê´€ì¤‘ ë“±) ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ”\n",
        "Semantic Segmentation ëª¨ë¸ì„ êµ¬í˜„í•˜ê³ , í•™ìŠµ ë° í‰ê°€ë¥¼ í†µí•´ ì„±ëŠ¥ê³¼ í•œê³„ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì´ë‹¤.\n",
        "\n",
        "ì¼ë°˜ ë¶„ë¥˜(Classification)ê°€ â€œì´ë¯¸ì§€ 1ì¥ = ë¼ë²¨ 1ê°œâ€ë¼ë©´,\n",
        "ì„¸ê·¸ë©˜í…Œì´ì…˜ì€ â€œì´ë¯¸ì§€ 1ì¥ = í”½ì…€ ìˆ˜ë§Œí¼ì˜ ë¼ë²¨â€ì„ ì˜ˆì¸¡í•´ì•¼ í•œë‹¤.  \n",
        "ì¦‰, ê°™ì€ ëª¨ë¸ì´ë¼ë„ ë‚œì´ë„ê°€ í›¨ì”¬ ë†’ê³ , íŠ¹íˆ ë°ì´í„°ê°€ ì ì„ ë•Œ ê³¼ì í•©ì´ ë§¤ìš° ì‰½ê²Œ ë°œìƒí•œë‹¤.\n",
        "\n",
        "\n",
        "## 2. ë°ì´í„°\n",
        "- ë°ì´í„°ì…‹: Football Semantic Segmentation (UEFA ìŠˆí¼ì»µ 2017 í•˜ì´ë¼ì´íŠ¸ ê¸°ë°˜)\n",
        "- êµ¬ì„±: ì´ 100ì¥ í”„ë ˆì„(12í”„ë ˆì„ ê°„ê²© ì¶”ì¶œ + ì¼ë¶€ ëŒ€ì²´)\n",
        "- í´ë˜ìŠ¤ ìˆ˜: 11ê°œ\n",
        "  - Goal Bar, Referee, Advertisement, Ground, Ball, Coaches & Officials, Audience, Goalkeeper A, Goalkeeper B, Team A, Team B\n",
        "\n",
        "\n",
        "## 3. ë¬¸ì œ ì„¤ì •ì—ì„œ ì¤‘ìš”í•œ ì \n",
        "- ë°ì´í„°ê°€ ë§¤ìš° ì ë‹¤(100ì¥) â†’ ì„¸ê·¸ë©˜í…Œì´ì…˜ì—ì„œ ê³¼ì í•©ì´ ì‚¬ì‹¤ìƒ ê¸°ë³¸ê°’ì²˜ëŸ¼ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤.\n",
        "- ë˜í•œ í”„ë ˆì„ ë°ì´í„°ëŠ” ì‹œê°„ì ìœ¼ë¡œ ì—°ì†ì„±ì´ ìˆë‹¤ â†’ ëœë¤ ë¶„í• ì€ â€œë¹„ìŠ·í•œ ì¥ë©´ì´ train/testì— ë™ì‹œì— ë“¤ì–´ê°€ëŠ” ëˆ„ìˆ˜â€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- ê·¸ë˜ì„œ GroupKFoldë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ìŠ·í•œ ê·¸ë£¹(í”„ë ˆì„ ë²ˆí˜¸ ê¸°ë°˜)ì´ ì„ì´ì§€ ì•Šë„ë¡ í‰ê°€ êµ¬ì¡°ë¥¼ ì¡ì•˜ë‹¤.\n",
        "\n",
        "\n",
        "## 4. ì „ì²´ ë¡œë“œë§µ\n",
        "1) ë°ì´í„° ë¡œë“œ ë° ë§ˆìŠ¤í¬(RGB) â†’ í´ë˜ìŠ¤ID ë³€í™˜ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•  \n",
        "2) Baseline U-Netìœ¼ë¡œ â€œì¼ë‹¨ ëŒì•„ê°€ëŠ”ì§€â€ ê²€ì¦(ë¹ ë¥¸ sanity check)  \n",
        "3) ì „ì´í•™ìŠµ U-Net(ResNet34 encoder) + feature extraction(encoder freeze) ì ìš©  \n",
        "4) ì†ì‹¤í•¨ìˆ˜ ê°œì„ (CE + Dice, í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜) + í•™ìŠµë¥ /ê·œì œ(weight_decay) íŠœë‹  \n",
        "5) í‰ê°€ ì§€í‘œëŠ” mIoU ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ë¡í•˜ê³ , ê²°ê³¼ ì´ë¯¸ì§€ëŠ” ì •ì„±ì ìœ¼ë¡œ í•¨ê»˜ í™•ì¸í•œë‹¤\n"
      ],
      "metadata": {
        "id": "kKEm2sDrgdeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ & ì„í¬íŠ¸"
      ],
      "metadata": {
        "id": "6vBLeO_2EyHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# segmentation_models_pytorch: ì „ì´í•™ìŠµ U-Netì„ ë¹ ë¥´ê²Œ ì“°ê¸° ìœ„í•´ ì‚¬ìš©\n",
        "# albumentations: ì´ë¯¸ì§€ ì¦ê°•ì„ \"ì„¸ê·¸ë©˜í…Œì´ì…˜ìš©(mask í•¨ê»˜ ë³€í™˜)\"ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì“°ê¸° ìœ„í•´ ì‚¬ìš©\n",
        "\n",
        "!pip -q install albumentations segmentation-models-pytorch kagglehub\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# ì¬í˜„ì„±ì„ ì¡°ê¸ˆì´ë¼ë„ ë†’ì´ê¸° ìœ„í•œ ì‹œë“œ ê³ ì •\n",
        "def seed_everything(seed=42):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n"
      ],
      "metadata": {
        "id": "-H1M7H8aEHFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ë°ì´í„° ë‹¤ìš´ë¡œë“œ + íŒŒì¼ ë§¤ì¹­(ì›ë³¸ jpg â†” fuse ë§ˆìŠ¤í¬)"
      ],
      "metadata": {
        "id": "q24JK4afMRA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# KaggleHubë¡œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
        "path = kagglehub.dataset_download(\"sadhliroomyprime/football-semantic-segmentation\")\n",
        "print(\"dataset path:\", path)\n",
        "\n",
        "image_folder = os.path.join(path, \"images\")\n",
        "file_list = os.listdir(image_folder)\n",
        "\n",
        "# ì›ë³¸(.jpg)ê³¼ fuse ë§ˆìŠ¤í¬ íŒŒì¼ì„ êµ¬ë¶„\n",
        "original_files = sorted([f for f in file_list if f.endswith(\".jpg\") and \"fuse\" not in f])\n",
        "fuse_files = sorted([f for f in file_list if \"fuse\" in f])\n",
        "\n",
        "# ì›ë³¸ íŒŒì¼ëª…ì—ì„œ base_nameì„ ì¶”ì¶œí•´ fuseì™€ ë§¤ì¹­\n",
        "image_pairs = []\n",
        "mask_files = []\n",
        "for orig_file in original_files:\n",
        "    base_name = orig_file.replace(\".jpg\", \"\")\n",
        "    fuse_file = next((f for f in fuse_files if base_name in f), None)\n",
        "    if fuse_file:\n",
        "        image_pairs.append((orig_file, fuse_file))\n",
        "        mask_files.append(fuse_file)\n",
        "\n",
        "print(\"pairs:\", len(image_pairs))  # 100 pairs\n"
      ],
      "metadata": {
        "id": "83IjUbZNMTNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ë°ì´í„° ìƒ˜í”Œ í™•ì¸(ì›ë³¸/ë§ˆìŠ¤í¬ 5ìŒ)"
      ],
      "metadata": {
        "id": "oe5PSoUAMaOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë§ˆìŠ¤í¬ê°€ ì œëŒ€ë¡œ ë¶™ì–´ìˆëŠ”ì§€ ì´ˆë°˜ì— ëˆˆìœ¼ë¡œ í™•ì¸í•˜ëŠ” ê²Œ ì„¸ê·¸ë©˜í…Œì´ì…˜ì—ì„  í•„ìˆ˜\n",
        "num_samples = 5\n",
        "sample_pairs = image_pairs[:num_samples]\n",
        "\n",
        "fig, axes = plt.subplots(num_samples, 2, figsize=(10, 4*num_samples))\n",
        "\n",
        "for i, (img_name, mask_name) in enumerate(sample_pairs):\n",
        "    img = cv2.cvtColor(cv2.imread(os.path.join(image_folder, img_name)), cv2.COLOR_BGR2RGB)\n",
        "    mask = cv2.cvtColor(cv2.imread(os.path.join(image_folder, mask_name)), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f\"Image: {img_name}\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    axes[i, 1].imshow(mask)\n",
        "    axes[i, 1].set_title(f\"Mask: {mask_name}\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vFPeQXePMeFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ë§ˆìŠ¤í¬(RGB) â†’ í´ë˜ìŠ¤ID ë§¤í•‘ ë§Œë“¤ê¸° + í´ë˜ìŠ¤ í”½ì…€ ìˆ˜ ì§‘ê³„"
      ],
      "metadata": {
        "id": "vFdriPIOMht5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - ì •ë‹µ ë§ˆìŠ¤í¬ëŠ” \"RGB ìƒ‰ìƒ\"ìœ¼ë¡œ í´ë˜ìŠ¤ë¥¼ í‘œí˜„í•œë‹¤.\n",
        "# - ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” RGBê°€ ì•„ë‹ˆë¼ \"í´ë˜ìŠ¤ ë²ˆí˜¸(0~10)\"ë¡œ ë°”ê¿”ì•¼ í•œë‹¤.\n",
        "# - ì¶”ê°€ë¡œ í´ë˜ìŠ¤ë³„ í”½ì…€ ìˆ˜ë¥¼ ì„¸ë©´, í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘(ê°€ì¤‘ì¹˜ loss)ì— í™œìš© ê°€ëŠ¥í•˜ë‹¤.\n",
        "\n",
        "def collect_unique_colors(image_folder, mask_files):\n",
        "    color_set = set()\n",
        "    for mf in mask_files:\n",
        "        mask = cv2.cvtColor(cv2.imread(os.path.join(image_folder, mf)), cv2.COLOR_BGR2RGB)\n",
        "        uniq = np.unique(mask.reshape(-1, 3), axis=0)\n",
        "        for c in uniq:\n",
        "            color_set.add(tuple(c))\n",
        "    return sorted(list(color_set))\n",
        "\n",
        "unique_colors = collect_unique_colors(image_folder, mask_files)\n",
        "print(\"unique colors:\", len(unique_colors))\n",
        "\n",
        "# ìƒ‰ìƒ -> ë¼ë²¨ id (0~10)\n",
        "color_to_label = {color: idx for idx, color in enumerate(unique_colors)}\n",
        "label_to_color = {v: k for k, v in color_to_label.items()}\n",
        "\n",
        "# í´ë˜ìŠ¤ë³„ í”½ì…€ ìˆ˜ ê³„ì‚°(ê°€ì¤‘ì¹˜ ì‚°ì¶œìš©)\n",
        "color_counts = {color: 0 for color in unique_colors}\n",
        "total_pixels = 0\n",
        "\n",
        "for mf in mask_files:\n",
        "    mask = cv2.cvtColor(cv2.imread(os.path.join(image_folder, mf)), cv2.COLOR_BGR2RGB)\n",
        "    flat = mask.reshape(-1, 3)\n",
        "    total_pixels += flat.shape[0]\n",
        "    uniq, counts = np.unique(flat, axis=0, return_counts=True)\n",
        "    for u, cnt in zip(uniq, counts):\n",
        "        u = tuple(u)\n",
        "        if u in color_counts:\n",
        "            color_counts[u] += int(cnt)\n",
        "\n",
        "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜(ë‹¨ìˆœ ì—­ë¹ˆë„ í˜•íƒœ)\n",
        "class_pixel_counts = np.array([color_counts[label_to_color[i]] for i in range(len(unique_colors))])\n",
        "class_weights = total_pixels / (len(unique_colors) * class_pixel_counts)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "print(\"class_weights_tensor shape:\", class_weights_tensor.shape)\n"
      ],
      "metadata": {
        "id": "MyB2hY7vMjw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ Dataset ì •ì˜(Albumentations í¬í•¨) + Transform ì •ì˜"
      ],
      "metadata": {
        "id": "OW69sBQdMp8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_transforms(is_train=True):\n",
        "    # - ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¦ê°•ì€ imageì™€ maskë¥¼ \"ê°™ì´\" ë³€í™˜í•´ì•¼ í•œë‹¤.\n",
        "    # - ë„ˆë¬´ ê³¼í•œ ì¦ê°•ì€ ì‘ì€ ë°ì´í„°ì—ì„œ ì˜¤íˆë ¤ í•´ê°€ ë  ìˆ˜ ìˆì–´, ê¸°ë³¸ì ì¸ ìˆ˜ì¤€ìœ¼ë¡œë§Œ êµ¬ì„±.\n",
        "    if is_train:\n",
        "        return A.Compose([\n",
        "            A.Resize(256, 256),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.3),\n",
        "            A.Normalize(),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(256, 256),\n",
        "            A.Normalize(),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "class FootballDataset(Dataset):\n",
        "    def __init__(self, image_files, mask_files, image_folder, color_to_label, transform=None):\n",
        "        self.image_files = image_files\n",
        "        self.mask_files = mask_files\n",
        "        self.image_folder = image_folder\n",
        "        self.color_to_label = color_to_label\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.image_folder, self.mask_files[idx])\n",
        "\n",
        "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "        mask_rgb = cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # RGB ë§ˆìŠ¤í¬ë¥¼ í´ë˜ìŠ¤ID ë§ˆìŠ¤í¬ë¡œ ë³€í™˜\n",
        "        mask_class = np.zeros(mask_rgb.shape[:2], dtype=np.uint8)\n",
        "        for color, label in self.color_to_label.items():\n",
        "            mask_class[(mask_rgb == color).all(axis=-1)] = label\n",
        "\n",
        "        if self.transform:\n",
        "            out = self.transform(image=image, mask=mask_class)\n",
        "            image = out[\"image\"]         # torch tensor (C,H,W)\n",
        "            mask_class = out[\"mask\"]     # numpy -> torch tensorë¡œ ë³€í™˜ í•„ìš”\n",
        "\n",
        "        return image, torch.tensor(mask_class, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "QmL2SipcMsz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ Baseline - ì¼ë‹¨ ëŒì•„ê°€ëŠ”ì§€ ì²´í¬\n",
        "- ì„¸ê·¸ë©˜í…Œì´ì…˜ì€ íŒŒì´í”„ë¼ì¸ì´ í•œ êµ°ë°ë§Œ í‹€ì–´ì ¸ë„ í•™ìŠµì´ ì „ë¶€ ë¬´ë„ˆì§„ë‹¤. ê·¸ë˜ì„œ ë¨¼ì € ê°„ë‹¨í•œ ì„¤ì •ìœ¼ë¡œ â€œí•™ìŠµ/ì˜ˆì¸¡/ì‹œê°í™”ê°€ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€â€ë¥¼ í™•ì¸í•œ ë’¤, ì „ì´í•™ìŠµ + êµì°¨ê²€ì¦ìœ¼ë¡œ ë„˜ì–´ê°."
      ],
      "metadata": {
        "id": "_FWImHahMwi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ Main ëª¨ë¸(ì „ì´í•™ìŠµ U-Net) ì •ì˜: ResNet34 encoder + freeze"
      ],
      "metadata": {
        "id": "Xoyz4YW2M-gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - ì‘ì€ ë°ì´í„°(100ì¥)ì—ì„œëŠ” ì „ì²´ë¥¼ ë‹¤ í•™ìŠµì‹œí‚¤ë©´ ê³¼ì í•©ì´ ë„ˆë¬´ ë¹¨ë¦¬ ì˜¨ë‹¤.\n",
        "# - ê·¸ë˜ì„œ encoderëŠ” ImageNetìœ¼ë¡œ í•™ìŠµëœ íŠ¹ì§•ì„ \"ê³ ì •\"í•˜ê³ ,\n",
        "#   decoder ì¤‘ì‹¬ìœ¼ë¡œ í•™ìŠµ(feature extraction)í•´ì„œ ì•ˆì •ì„±ì„ ë†’ì¸ë‹¤.\n",
        "\n",
        "def get_model():\n",
        "    model = smp.Unet(\n",
        "        encoder_name=\"resnet34\",\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=11\n",
        "    )\n",
        "    # encoder freeze\n",
        "    for p in model.encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "uG7OtN0YMw7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ Loss(Dice) + CombinedLoss(CE+Dice) + mIoU í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "-nfz9PUrNEXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice Loss: ê²¹ì¹¨(ìœ ì‚¬ë„)ì„ ì§ì ‘ ìµœì í™”í•˜ë ¤ëŠ” ëª©ì  - ì„¸ê·¸ë©˜í…Œì´ì…˜ì— ìì£¼ ì‚¬ìš©\n",
        "def dice_loss(pred, target, num_classes=11, smooth=1e-7):\n",
        "    # pred: (B, C, H, W) logits\n",
        "    pred_soft = F.softmax(pred, dim=1)\n",
        "\n",
        "    # target: (B, H, W) -> one-hot: (B, C, H, W)\n",
        "    target_oh = F.one_hot(target, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
        "\n",
        "    intersection = torch.sum(pred_soft * target_oh, dim=(2, 3))\n",
        "    union = torch.sum(pred_soft, dim=(2, 3)) + torch.sum(target_oh, dim=(2, 3))\n",
        "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "    return 1.0 - dice.mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    # - CEëŠ” í”½ì…€ ë‹¨ìœ„ ë¶„ë¥˜ë¥¼ ì˜ ì¡ì•„ì£¼ê³ ,\n",
        "    # - DiceëŠ” \"ì˜ì—­ ê²¹ì¹¨\"ì„ ë°€ì–´ì£¼ëŠ” ì„±ê²©ì´ë¼ ë‘˜ì„ ì„ìœ¼ë©´ ì„±ëŠ¥ì´ ì•ˆì •ë˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.\n",
        "    def __init__(self, alpha=0.3, weight=None):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.ce = nn.CrossEntropyLoss(weight=weight)\n",
        "    def forward(self, pred, target):\n",
        "        return self.alpha * self.ce(pred, target) + (1 - self.alpha) * dice_loss(pred, target)\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_miou(pred, target, num_classes=11):\n",
        "    pred_cls = torch.argmax(pred, dim=1)  # (B,H,W)\n",
        "    ious = []\n",
        "    for cls in range(num_classes):\n",
        "        pred_inds = (pred_cls == cls)\n",
        "        tgt_inds = (target == cls)\n",
        "        intersection = (pred_inds & tgt_inds).sum().item()\n",
        "        union = (pred_inds | tgt_inds).sum().item()\n",
        "        if union == 0:\n",
        "            ious.append(np.nan)\n",
        "        else:\n",
        "            ious.append(intersection / union)\n",
        "    return float(np.nanmean(ious))\n"
      ],
      "metadata": {
        "id": "477OkrM_NGLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸GroupKFoldìš© ê·¸ë£¹ ìƒì„±(í”„ë ˆì„ ë²ˆí˜¸ ê¸°ë°˜)"
      ],
      "metadata": {
        "id": "rHvK1fpmNO9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - í”„ë ˆì„ ë°ì´í„°ëŠ” ì„œë¡œ ë§¤ìš° ë¹„ìŠ·í•œ ì¥ë©´ì´ ì—°ì†ìœ¼ë¡œ ë“±ì¥í•œë‹¤.\n",
        "# - ëœë¤ splitì´ë©´ \"ë¹„ìŠ·í•œ ì¥ë©´ì´ train/valì— ë™ì‹œì— ë“¤ì–´ê°€ëŠ” ëˆ„ìˆ˜\"ê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.\n",
        "# - ê·¸ë˜ì„œ íŒŒì¼ëª…ì— ë“¤ì–´ìˆëŠ” ìˆ«ì(í”„ë ˆì„ ë²ˆí˜¸)ë¥¼ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ GroupKFoldë¥¼ êµ¬ì„±í•œë‹¤.\n",
        "\n",
        "def extract_number(s):\n",
        "    m = re.findall(r\"\\d+\", s)\n",
        "    return int(m[0]) if m else 0\n",
        "\n",
        "groups = np.array([extract_number(f) for f in original_files])\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "print(\"example groups:\", groups[:10])\n"
      ],
      "metadata": {
        "id": "PwFgcFJMNR_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸1 Fold í•™ìŠµ í•¨ìˆ˜(run_fold) + Warmup/Poly LR + EarlyStopping"
      ],
      "metadata": {
        "id": "zYnIh9EoNVfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def warmup_poly_lr_lambda(epoch, warmup_epochs=5, max_epochs=50, power=0.9):\n",
        "    # - Warmup: ì´ˆë°˜ í•™ìŠµ ë¶ˆì•ˆì • ì™„í™”\n",
        "    # - Poly decay: segmentationì—ì„œ ìì£¼ ì“°ëŠ” ì•ˆì •ì ì¸ decay í˜•íƒœ\n",
        "    if epoch < warmup_epochs:\n",
        "        return (epoch + 1) / warmup_epochs\n",
        "    else:\n",
        "        t = (epoch - warmup_epochs) / max(1, (max_epochs - warmup_epochs))\n",
        "        return (1 - t) ** power\n",
        "\n",
        "def run_fold(fold, model, train_ds, val_ds, class_weights_tensor, device, max_epochs=50, patience=10):\n",
        "    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0)\n",
        "\n",
        "    criterion = CombinedLoss(alpha=0.3, weight=class_weights_tensor)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer,\n",
        "        lr_lambda=lambda e: warmup_poly_lr_lambda(e, warmup_epochs=5, max_epochs=max_epochs)\n",
        "    )\n",
        "\n",
        "    best_val_miou = -1\n",
        "    best_wts = copy.deepcopy(model.state_dict())\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for imgs, masks in train_loader:\n",
        "            imgs, masks = imgs.to(device), masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(imgs)               # (B, C, H, W)\n",
        "            loss = criterion(logits, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= max(1, len(train_loader))\n",
        "\n",
        "        # ---- val ----\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_miou = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, masks in val_loader:\n",
        "                imgs, masks = imgs.to(device), masks.to(device)\n",
        "                logits = model(imgs)\n",
        "                val_loss += criterion(logits, masks).item()\n",
        "                val_miou.append(calculate_miou(logits, masks, num_classes=11))\n",
        "\n",
        "        val_loss /= max(1, len(val_loader))\n",
        "        avg_val_miou = float(np.mean(val_miou))\n",
        "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        # ë¡œê·¸(ë„¤ ë…¸íŠ¸ë¶ ìŠ¤íƒ€ì¼ ë°˜ì˜)\n",
        "        msg = f\"Epoch [{epoch+1}/{max_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val mIoU: {avg_val_miou:.4f}, LR: {current_lr:.6f}\"\n",
        "        if avg_val_miou > best_val_miou:\n",
        "            best_val_miou = avg_val_miou\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "            msg += \" = BEST\"\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(msg)\n",
        "        scheduler.step()\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Fold {fold+1} ì™„ë£Œ Best Val mIoU: {best_val_miou:.4f}\\n\")\n",
        "    return best_val_miou, best_wts\n"
      ],
      "metadata": {
        "id": "Dd86zD3VNaAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ K-Fold ì‹¤í–‰ + ìµœê³  Fold ëª¨ë¸ ì €ì¥ + ì „ì²´ mIoU í‰ê°€"
      ],
      "metadata": {
        "id": "Y6VjNuO0Nzu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fold_best = []\n",
        "fold_wts = []\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(gkf.split(original_files, groups=groups)):\n",
        "    train_imgs = [original_files[i] for i in tr_idx]\n",
        "    train_masks = [mask_files[i] for i in tr_idx]\n",
        "    val_imgs = [original_files[i] for i in va_idx]\n",
        "    val_masks = [mask_files[i] for i in va_idx]\n",
        "\n",
        "    train_ds = FootballDataset(train_imgs, train_masks, image_folder, color_to_label, transform=get_transforms(True))\n",
        "    val_ds   = FootballDataset(val_imgs,   val_masks,   image_folder, color_to_label, transform=get_transforms(False))\n",
        "\n",
        "    model = get_model().to(device)\n",
        "    best_miou, best_wts = run_fold(fold, model, train_ds, val_ds, class_weights_tensor, device)\n",
        "\n",
        "    fold_best.append(best_miou)\n",
        "    fold_wts.append(best_wts)\n",
        "\n",
        "best_fold = int(np.argmax(fold_best))\n",
        "print(\"best_fold:\", best_fold+1, \"best_val_miou:\", fold_best[best_fold])\n",
        "\n",
        "# best fold weights ë¡œë“œ\n",
        "best_model = get_model().to(device)\n",
        "best_model.load_state_dict(fold_wts[best_fold])\n",
        "best_model.eval()\n",
        "\n",
        "# ì „ì²´ ë°ì´í„° mIoU í‰ê°€(ë„¤ ë…¸íŠ¸ë¶ ë¡œê·¸: Final mIoU on the entire dataset: 0.4615)\n",
        "full_ds = FootballDataset(original_files, mask_files, image_folder, color_to_label, transform=get_transforms(False))\n",
        "full_loader = DataLoader(full_ds, batch_size=4, shuffle=False, num_workers=0)\n",
        "\n",
        "miou_list = []\n",
        "with torch.no_grad():\n",
        "    for imgs, masks in full_loader:\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        logits = best_model(imgs)\n",
        "        miou_list.append(calculate_miou(logits, masks, num_classes=11))\n",
        "\n",
        "final_miou = float(np.mean(miou_list))\n",
        "print(f\"Final mIoU on the entire dataset: {final_miou:.4f}\")\n",
        "\n",
        "'''\n",
        "Fold Best Val mIoU ì˜ˆì‹œ: 0.5359\n",
        "Final mIoU: 0.4615\n",
        "'''"
      ],
      "metadata": {
        "id": "4h6XfqnoN2VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ì‹œê°í™”(ì›ë³¸ / GT / Pred) + ìƒ‰ìƒ ì…íˆê¸°\n",
        "- ì ìˆ˜ë§Œ ë³´ë©´ â€œì¢‹ì•„ì§„ ê²ƒì²˜ëŸ¼â€ ë³´ì—¬ë„, ì‹¤ì œ ë¶„í• ì´ ì´ìƒí•˜ê²Œ ê¹¨ì§€ëŠ” ê²½ìš°ê°€ ìˆì–´ ì„¸ê·¸ë©˜í…Œì´ì…˜ì€ ì‹œê°í™”ê°€ í•„ìˆ˜ë‹¤."
      ],
      "metadata": {
        "id": "ugmIDvjmN7vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_rgb(mask_2d, label_to_color):\n",
        "    h, w = mask_2d.shape\n",
        "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    for lbl, color in label_to_color.items():\n",
        "        rgb[mask_2d == lbl] = np.array(color, dtype=np.uint8)\n",
        "    return rgb\n",
        "\n",
        "# ëª‡ ì¥ë§Œ í™•ì¸\n",
        "indices = [0, 10, 20, 30, 40]\n",
        "fig, axes = plt.subplots(len(indices), 3, figsize=(12, 4*len(indices)))\n",
        "\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    for r, idx in enumerate(indices):\n",
        "        img_t, gt = full_ds[idx]\n",
        "        logits = best_model(img_t.unsqueeze(0).to(device))\n",
        "        pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "        # albumentations normalizeëœ ì´ë¯¸ì§€ë¥¼ í™”ë©´ìš©ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°(ëŒ€ëµì )\n",
        "        img_np = img_t.permute(1,2,0).cpu().numpy()\n",
        "        img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
        "\n",
        "        gt_rgb = mask_to_rgb(gt.cpu().numpy(), label_to_color)\n",
        "        pred_rgb = mask_to_rgb(pred, label_to_color)\n",
        "\n",
        "        axes[r, 0].imshow(img_np); axes[r, 0].set_title(\"Image\"); axes[r, 0].axis(\"off\")\n",
        "        axes[r, 1].imshow(gt_rgb); axes[r, 1].set_title(\"GT Mask\"); axes[r, 1].axis(\"off\")\n",
        "        axes[r, 2].imshow(pred_rgb); axes[r, 2].set_title(\"Pred Mask\"); axes[r, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9n58QVWnN-8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŸ¨ ìµœì¢… ê²°ë¡  ë° ë¶„ì„\n",
        "\n",
        "---\n",
        "\n",
        "## 1. ê²°ê³¼ ìš”ì•½\n",
        "ë³¸ ì‹¤í—˜ì—ì„œëŠ” ì¶•êµ¬ ê²½ê¸° ì¥ë©´(100ì¥)ì—ì„œ 11ê°œ í´ë˜ìŠ¤ë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” U-Net ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ êµ¬ì¶•í–ˆë‹¤.\n",
        "ë°ì´í„°ê°€ ë§¤ìš° ì ê³ (100ì¥), í”„ë ˆì„ íŠ¹ì„±ìƒ ì‹œê°„ì  ìœ ì‚¬ì„±ì´ ê°•í•´ ë°ì´í„° ëˆ„ìˆ˜ ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì—,\n",
        "í‰ê°€ êµ¬ì¡°ëŠ” GroupKFoldë¡œ ì„¤ê³„í–ˆë‹¤.\n",
        "\n",
        "- êµì°¨ê²€ì¦ ì¤‘ ìµœê³  ì„±ëŠ¥(Best Val mIoU): 0.5359\n",
        "- ì „ì²´ ë°ì´í„° ê¸°ì¤€ ìµœì¢… í‰ê°€(Final mIoU): 0.4615\n",
        "\n",
        "---\n",
        "\n",
        "## 2. ê´€ì°°ëœ í˜„ìƒ\n",
        "1) ê³¼ì í•©ì´ ì‰½ê²Œ ë°œìƒí•œë‹¤\n",
        "- ë°ì´í„° ìˆ˜ê°€ ì ê³  í´ë˜ìŠ¤ëŠ” 11ê°œë¡œ ë§ì•„, ëª¨ë¸ì´ â€œì¼ë°˜ì ì¸ ê·œì¹™â€ë³´ë‹¤ â€œíŠ¹ì • ì¥ë©´â€ì„ ì™¸ìš°ê¸° ì‰¬ì› ë‹¤.\n",
        "- ì‹¤ì œë¡œ í•™ìŠµì´ ì§„í–‰ë˜ë©° train ì§€í‘œëŠ” ì¢‹ì•„ì§€ëŠ”ë°, val ì„±ëŠ¥ì´ ë¶ˆì•ˆì •í•˜ê±°ë‚˜ ì •ì„± ê²°ê³¼ê°€ ì˜¤íˆë ¤ ë§ê°€ì§€ëŠ” íŒ¨í„´ì„ í™•ì¸í–ˆë‹¤.\n",
        "\n",
        "2) ì´ ë¯¸ì…˜ì—ì„œëŠ” partial fine-tuningë³´ë‹¤ feature extractionì´ ë” ì•ˆì •ì ì´ì—ˆë‹¤\n",
        "- ì¸ì½”ë”(ResNet34)ë¥¼ freezeí•˜ê³  ë””ì½”ë” ì¤‘ì‹¬ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.\n",
        "- ì‘ì€ ë°ì´í„°ì—ì„œëŠ” í•™ìŠµ ììœ ë„ê°€ í° ë°©ì‹(partial FT)ì´ ì˜¤íˆë ¤ ê³¼ì í•©ì„ ë” ë¹ ë¥´ê²Œ ë§Œë“ ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "3) ì†ì‹¤í•¨ìˆ˜ì™€ ê·œì œ/í•™ìŠµë¥ ì´ ì„±ëŠ¥ì— ë¯¼ê°í–ˆë‹¤\n",
        "- CE ë‹¨ë…ë³´ë‹¤ CE+Dice ì¡°í•©ì´ val mIoU ê°œì„ ì— ë„ì›€ì„ ì£¼ì—ˆë‹¤.\n",
        "- ë˜í•œ learning rateì™€ weight_decay ì¡°ì •ë§Œìœ¼ë¡œë„ ì„±ëŠ¥ì´ ìœ ì˜ë¯¸í•˜ê²Œ í”ë“¤ë ¸ë‹¤.\n",
        "  ì¦‰, ì´ ë¬¸ì œëŠ” â€œëª¨ë¸ ë°”ê¾¸ê¸°â€ë³´ë‹¤ â€œí•™ìŠµ ì•ˆì •í™”â€ì˜ ì˜í–¥ì´ í° í™˜ê²½ì´ì—ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. í•œê³„\n",
        "- ë°ì´í„°ê°€ 100ì¥ìœ¼ë¡œ ì§€ë‚˜ì¹˜ê²Œ ì ì–´, ì •ëŸ‰ ì§€í‘œ(mIoU)ê°€ íŠ¹ì • ë¶„í•  ë°©ì‹ì— í¬ê²Œ ì˜ì¡´í•  ìˆ˜ ìˆë‹¤.\n",
        "- RGB ë§ˆìŠ¤í¬ ìƒ‰ìƒ â†’ í´ë˜ìŠ¤ ID ë§¤í•‘ì´ ë°ì´í„° ë¡œë”© ë‹¨ê³„ì—ì„œ ê²°ì •ë˜ë¯€ë¡œ, ë§¤í•‘ì„ ê³ ì •/ê²€ì¦í•˜ì§€ ì•Šìœ¼ë©´ ì¬í˜„ì„±ì´ í”ë“¤ë¦´ ìˆ˜ ìˆë‹¤.\n",
        "- ê²°ê³¼ ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œëŠ” â€œì ìˆ˜ëŠ” ê´œì°®ì•„ë„ ì‹œê°ì ìœ¼ë¡œëŠ” ë” ì—‰ë§â€ì¸ ì‚¬ë¡€ê°€ ì¡´ì¬í–ˆëŠ”ë°,\n",
        "  ì´ëŠ” ì‘ì€ ë°ì´í„°ì—ì„œ ì§€í‘œ ìµœì í™”ê°€ ê³§ë°”ë¡œ ì •ì„± í’ˆì§ˆë¡œ ì´ì–´ì§€ì§€ ì•Šì„ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ë‹¤ìŒ ê°œì„  ë°©í–¥\n",
        "- ë°ì´í„° ì¦ê°•ì„ â€œê³¼í•˜ê²Œâ€ ë„£ê¸°ë³´ë‹¤, ì‹¤ì œ ê²½ê¸° í™˜ê²½ ë³€í™”(ë°ê¸°/ìƒ‰ìƒ/ì¢Œìš°ë°˜ì „ ë“±)ì— ë§ê²Œ ì œí•œì ìœ¼ë¡œ ì ìš©\n",
        "- í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ì‹¬í•œ í´ë˜ìŠ¤(ê³µ, ê³¨ëŒ€ ë“±)ì— ëŒ€í•´ ê°€ì¤‘ì¹˜/ìƒ˜í”Œë§ ì „ëµì„ ì¶”ê°€ ê²€í† \n",
        "- ì¡°ê±´ì´ í—ˆìš©ëœë‹¤ë©´ í”„ë ˆì„ ìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜(ë” ë§ì€ ì˜ìƒ í”„ë ˆì„), ë™ì¼ ê²½ê¸° ì™¸ ë‹¤ë¥¸ ê²½ê¸°ë¡œ ë„ë©”ì¸ì„ í™•ì¥í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ í™•ì¸\n",
        "\n",
        "---\n",
        "\n",
        "## 5. ê²°ë¡ \n",
        "ì†Œê·œëª¨ ì¶•êµ¬ í”„ë ˆì„ ë°ì´í„°ì—ì„œ U-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ êµ¬í˜„í•˜ê³ , ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€(GroupKFold), ì „ì´í•™ìŠµ(feature extraction), ì†ì‹¤í•¨ìˆ˜(CE+Dice) ë° í•™ìŠµ ì•ˆì •í™”(ê·œì œ/ìŠ¤ì¼€ì¤„)ë¥¼ í†µí•´\n",
        "mIoU ê¸°ì¤€ ì„±ëŠ¥ ê°œì„ ì„ í™•ì¸í–ˆë‹¤.\n",
        "ë‹¤ë§Œ ë°ì´í„° í•œê³„ë¡œ ê³¼ì í•©ì´ ê°•í•˜ê²Œ ë‚˜íƒ€ë‚˜ë¯€ë¡œ, ì´í›„ ì‹¤í—˜ì€ â€œì¼ë°˜í™”â€ë¥¼ ëª©í‘œë¡œ ë°ì´í„°/í‰ê°€ êµ¬ì¡°ì˜ ë³´ê°•ì´ í•„ìš”í•˜ë‹¤.\n"
      ],
      "metadata": {
        "id": "u6lcjh0_hCFA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soDBqNuSgZNK"
      },
      "outputs": [],
      "source": []
    }
  ]
}